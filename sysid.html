<!DOCTYPE html>

<html>

  <head>
    <title>Underactuated Robotics: System Identification</title>
    <meta name="Underactuated Robotics: System Identification" content="text/html; charset=utf-8;" />
    <link rel="canonical" href="http://underactuated.mit.edu/sysid.html" />

    <script src="https://hypothes.is/embed.js" async></script>
    <script type="text/javascript" src="htmlbook/book.js"></script>

    <script src="htmlbook/mathjax-config.js" defer></script> 
    <script type="text/javascript" id="MathJax-script" defer
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script>window.MathJax || document.write('<script type="text/javascript" src="htmlbook/MathJax/es5/tex-chtml.js" defer><\/script>')</script>

    <link rel="stylesheet" href="htmlbook/highlight/styles/default.css">
    <script src="htmlbook/highlight/highlight.pack.js"></script> <!-- http://highlightjs.readthedocs.io/en/latest/css-classes-reference.html#language-names-and-aliases -->
    <script>hljs.initHighlightingOnLoad();</script>

    <link rel="stylesheet" type="text/css" href="htmlbook/book.css" />
  </head>

<body onload="loadChapter('underactuated');">

<div data-type="titlepage">
  <header>
    <h1><a href="index.html" style="text-decoration:none;">Underactuated Robotics</a></h1>
    <p data-type="subtitle">Algorithms for Walking, Running, Swimming, Flying, and Manipulation</p> 
    <p style="font-size: 18px;"><a href="http://people.csail.mit.edu/russt/">Russ Tedrake</a></p>
    <p style="font-size: 14px; text-align: right;"> 
      &copy; Russ Tedrake, 2021<br/>
      Last modified <span id="last_modified"></span>.</br>
      <script>
      var d = new Date(document.lastModified);
      document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      <a href="misc.html">How to cite these notes, use annotations, and give feedback.</a><br/>
    </p>
  </header>
</div>

<p><b>Note:</b> These are working notes used for <a
href="http://underactuated.csail.mit.edu/Spring2021/">a course being taught
at MIT</a>. They will be updated throughout the Spring 2021 semester.  <a 
href="https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg">Lecture  videos are available on YouTube</a>.</p> 

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=contact.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=state_estimation.html>Next Chapter</a></td>
</tr></table>


<!-- EVERYTHING ABOVE THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->
<chapter style="counter-reset: chapter 17"><h1>System Identification</h1>
  <a style="float:right; margin-top:-80px;" target="sysid" href="https://colab.research.google.com/github/RussTedrake/underactuated/blob/master/sysid.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open Corresponding Notebook In Colab"/></a>
  <div style="clear:right;"></div>

  <p>My primary focus in these notes has been to build algorithms that design
  of analyze a control system <i>given a model</i> of the plant.  In fact, we
  have in some places gone to great lengths to understand the structure in our
  models (the structure of the manipulator equations in particular) and tried
  to write algorithms which exploit that structure.</p>

  <p>Our ambitions for our robots have grown over recent years to where it
  makes sense to question this assumption.  If we want to program a robot to
  fold laundry, spread peanut butter on toast, or make a salad, then we should
  absolutely not assume that we are simply given a model (and the ability to
  estimate the state of that model).  This has led many researchers to focus on
  the "model-free" approaches to optimal control that are popular in
  reinforcement learning.  But I worry that the purely model-free approach is
  "throwing the baby out with the bathwater".  We have fantastic tools for
  making long-term decisions given a model; the model-free approaches are
  correspondingly much much weaker.</p>

  <p>So in this chapter I would like to cover the problem of learning a model.
  This is far from a new problem.  The field of "system identification" is as
  old as controls itself, but new results from machine learning have added
  significantly to our algorithms and our analyses, especially in the
  high-dimensional and finite-sample regimes.  But well before the recent
  machine learning boom, system identification as a field had a very strong
  foundation with thorough statistical understanding of the basic algorithms,
  at least in the asymptotic regime (the limit where the amount of data goes to
  infinity).  My goal for this chapter is to establish this foundation, and to
  provide some pointers, but I will stop short of providing the full
  statistical viewpoint here.</p>

  <section><h1>Problem formulation: equation error vs simulation error</h1>
  
    <figure><img width="80%"" src="data/sysid.svg"/></figure>

    <p>Our problem formulation inevitably begins with the data.  In practice,
    if we have access to a physical system, instrumented using digital
    electronics, then we have a system in which we can apply input commands,
    $\bu_n$, at some discrete rate, and measure the outputs, $\by_n$ of the
    system at some discrete rate.  We normally assume these rates our fixed,
    and often attempt to fit a state-space model of the form \begin{equation}
    \bx[n+1] = f_\balpha(\bx[n], \bu[n]), \qquad \by[n] =
    g_\balpha(\bx[n],\bu[n]), \label{eq:ss_model}\end{equation} where I have
    used $\balpha$ again here to indicate a vector of parameters.  In this
    setting, a natural formulation is to minimize a least-squares estimation
    objective: $$\min_{\alpha,\bx[0]} \sum_{n=0}^{N-1} \| \by[n] - \by_n
    \|^2_2, \qquad \subjto \, (\ref{eq:ss_model}).$$  I have written purely
    deterministic models to start, but in general we expect both the state
    evolution and the measurements to have randomness.  Sometimes, as I
    have written, we fit a deterministic model to the data and rely on our
    least-squares objective to capture the errors; more generally we will look
    at fitting stochastic models to the data.</p>
    
    <p>We often separate the identification procedure into two parts, were we
    first estimate the state $\hat{\bx}_n$ given the input-output data $\bu_n,
    \by_n$, and then focus on estimating the state-evolution dynamics in a
    second step.  The dynamics estimation algorithms fall into two main
    categories: <ul><li><i>Equation error</i> minimizes only the one-step
    prediction error: $$\min_{\alpha} \sum_{n=0}^{N-2} \| f_\balpha(\hat\bx_n,
    \bu_n) - \hat{\bx}_{n+1} \|^2_2.$$  </li><li><i>Simulation error</i>
    captures the long-term prediction error: $$\min_{\alpha} \sum_{n=1}^{N-1}
    \| \bx[n] - \hat{\bx}_n \|^2_2, \qquad \subjto \quad \bx[n+1] =
    f_\balpha(\bx[n], \bu_n), \bx[0] = \hat\bx_0,$$ </li></ul>  The
    equation-error formulations often result in much more tractable
    optimization problems, but unfortunately we will see that optimizing the
    one-step error can still result in arbitrarily large simulation errors.
    Therefore, we generally consider the simulation error to be the true
    objective we hope to optimize, and the equation error only as a potentially
    useful surrogate.</p>
  
  </section>

  <section><h1>Parameter Identification for Mechanical Systems</h1>

    <p>My primary focus throughout these notes is on (underactuated) mechanical
    systems, but when it comes to identification there is an important
    distinction to make.  For some mechanical systems we know the structure of
    the model, including number of state variables and the topology of the
    kinematic tree.  Legged robots like Spot or Atlas are good examples here --
    the dynamics are certainly nontrivial, but the general form of the
    equations are known.  In this case, the task of identification is really
    the task of estimating the parameters in a structured model.  That is the
    subject of this section.</p>

    <p>The examples of folding laundry or making a salad fall into a different
    category.  In those examples, I might not even know a priori the number of
    state variables needed to provide a reasonable description of the behavior.
    That will force a more general examination of the the identification
    problem, which we will explore in the remaining sections.</p>

    <p>Let's start with the problem of identifying a canonical underactuated
    mechanical system, like an Acrobot, Cart-Pole or Quadrotor, where we know
    the structure of the equations, but just need to fit the parameters.  We
    will further assume that we have the ability to directly observe all of the
    state variables, albeit with noisy measurements (e.g. from joint sensors
    and/or inertial measurement units).  The stronger <a
    href="state_estimation.html">state estimation algorithms</a> that we
    will discuss soon assume a model, so we typically do not use them directly
    here.</p>

    <p>Consider taking a minute to review the <a
    href="multibody.html#double_pendulum">example of deriving the manipulator
    equations for the double pendulum</a> before we continue.</p>

    <subsection><h1>Kinematic parameters and calibration</h1>

      <p>We can separate the parameters in the multibody equations again into
      kinematic parameters and dynamic parameters.  The kinematic parameters,
      like link lengths, describe the coordinate transformation from one joint
      to another joint in the kinematic tree.  It is certainly possible to
      write an optimization procedure to calibrate these parameters; you can
      find a fairly thorough discussion in e.g. Chapter 11 of
      <elib>Khalil04</elib>. But I guess I'm generally of the opinion that if
      you don't have accurate estimates of your link lengths, then you should
      probably invest in a tape measure before you invest in nonlinear
      optimization.</p>

      <p>One notable exception to this is calibration with respect to joint
      offsets.  This one can be a real nuisance in practice.  Joint sensors can
      slip, and some robots even use relative rotary encoders, and rely on
      driving the joint to some known hard joint limit each time the robot is
      powered on in order to obtain the offset.  I've worked on one humanoid
      robot that had a quite elaborate and painful kinematic calibration
      procedure which involve fitting additional hardware over the joints to
      ensure they were in a known location and then running a script.  Having a
      an expensive and/or unreliable calibration procedure can put a damper on
      any robotics project.  For underactuated systems, in particular, it can
      have a dramatic effect on performance.</p>
    
      <example><h1>Acrobot balancing with calibration error</h1>
      
        <p>Small kinematic calibration errors can lead to large steady-state
        errors when attempting to stabilize a system like the Acrobot.  I've put together a simple notebook to show the effect here:</p>

        <p><a target="sysid"
          href="https://colab.research.google.com/github/RussTedrake/underactuated/blob/master/sysid.ipynb#scrollTo=ASlp7CDoQL5t"><img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"/></a>
            </p>

        <todo>Make a plot of steady-state error as a function of offset error.</todo>

        <p>Our tools from robust / stochastic control are well-suited to
        identifying (and bounding / minimizing) these sensitivities, at least
        for the linearized model we use in LQR.</p>
      </example>

      <p>The general approach to estimating joint offsets from data is to write
      the equations with the joint offset as a parameter, e.g. for the <a
      href="multibody.html#double_pendulum">double pendulum</a> we would write
      the forward kinematics as:  $${\bf p}_1 =l_1\begin{bmatrix} \sin(\theta_1
      + \bar\theta_1) \\ - \cos(\theta_1 + \bar\theta_1) \end{bmatrix},\quad
      {\bf p}_2  =      {\bf p}_1 + l_2\begin{bmatrix} \sin(\theta_1 +
      \bar\theta_1 + \theta_2 + \bar\theta_2) \\ - \cos(\theta_1 + \bar\theta_1
      + \theta_2 + \bar\theta_2) \end{bmatrix}.$$  We try to obtain independent
      measurements of the end-effector position (e.g. from motion capture, from
      perhaps some robot-mounted cameras, or from some mechanical calibration
      rig) with their corresponding joint measurements, to obtain data points
      of the form $ \langle {\bf p}_2, \theta_1, \theta_2 \rangle$. Then we can
      solve a small nonlinear optimization problem to estimate the joint
      offsets to minimize a least-squares residual.</p>

      <p>If independent measurements of the kinematics are not available, it it
      possible to estimate the offsets along with the dynamic parameters, using
      the trigonometric identities, e.g. $s_{\theta + \bar\theta} = s_\theta
      c_\bar\theta + c_\theta s_\bar\theta,$ and then including the
      $s_\bar\theta, c_\bar\theta$ terms (separately) in the "lumped
      parameters" we discuss below.</p>

    </subsection>

    <subsection><h1>Least-squares formulation (of the inverse dynamics).</h1>

      <p>Now let's thinking about estimating the dynamic parameters of
      multibody system.  We've been writing the manipulation equations in the
      form: \begin{equation}\bM({\bq})\ddot{\bq} + \bC(\bq,\dot{\bq})\dot\bq =
      \btau_g(\bq) + \bB\bu + \text{friction, etc.}\end{equation}  Each of the
      terms in this equation can depend on the parameters $\balpha$ that we're
      trying to estimate.  But the parameters enter the multibody equations in
      a particular structured way: the equations are
      <i>affine in the <b>lumped parameters</b></i>.  More precisely, the
      manipulator equations above can be factored into the form $${\bf
      W}(\bq,\dot{\bq}, \ddot{\bq}, \bu) \balpha_l(\balpha) +
      \bw_0(\bq,\dot{\bq}, \ddot{\bq}, \bu) = 0,$$ where $\balpha_l$ are the
      "lumped parameters".  We sometimes refer to ${\bf W}$ as the "data matrix".</p>

      <example><h1>Lumped parameters for the simple pendulum</h1>
        
        <p>The now familiar equations of motion for the simple pendulum are
        $$ml^2 \ddot\theta + b \dot\theta + mgl\sin\theta = \tau.$$  For
        parameter estimation, we will factor this into $$\begin{bmatrix}
        \ddot\theta & \dot\theta & \sin\theta \end{bmatrix} \begin{bmatrix}
        ml^2 \\ b \\ mgl \end{bmatrix} - \tau = 0.$$  The terms $ml^2$, $b$,
        and $mgl$ together form the "lumped parameters".</p>
      
      </example>

      <p>It is worth taking a moment to reflect on this factorization.  First
      of all, it does represent a somewhat special statement about the
      multibody equations: the nonlinearities enter only in a particular way.
      For instance, if I had terms in the equations of the form, $\sin(m
      \theta)$, then I would <i>not</i> be able to produce an affine
      decomposition separating $m$ from $\theta$.  Fortunately, that doesn't
      happen in our mechanical systems <elib>Khalil04</elib>.  Furthermore,
      this structure is particular to the <i>inverse dynamics</i>, as we have
      written here.  If you were to write the forward dynamics, multiplying by
      $\bM^{-1}$ in order to solve for $\ddot{\bq}$, then once again you would
      destroy this affine structure.</p>
      
      <p>This is super interesting!  It is tempting to thing about parameter
      estimation for general dynamical systems in our standard state-space
      form: $\bx[n+1] = f_\balpha(\bx[n], \bu[n]).$  But for multibody systems,
      it seems that this would be the wrong thing to do, as it destroys this
      beautiful affine structure.</p>

      <example><h1>Multibody parameters in <drake></drake></h1>
      
        <p>Very few robotics simulators have any way for you to access the
        parameters of the dynamics.  In Drake, we explicitly declare all of the
        parameters of a multibody system in a separate data structure to make
        them available, and we can leverage Drake's symbolic engine to extract
        and manipulate the equations with respect to those variables.
        </p>
        
        <p>As a simple example, I've loaded the cart-pole system model from
        URDF, created a symbolic version of the <code>MultibodyPlant</code>,
        and populated the <code>Context</code> with symbolic variables for the
        quantities of interest.  Then I can evaluate the (inverse) dynamics in
        order to obtain my equations.</p>

        <p><a target="sysid"
          href="https://colab.research.google.com/github/RussTedrake/underactuated/blob/master/sysid.ipynb#scrollTo=ASlp7CDoQL5t"><img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"/></a>
            </p>

        <p>The output looks like: <pre><code>Symbolic dynamics:
(0.10000000000000001 * v(0) - u(0) + (pow(v(1), 2) * mp * l * sin(q(1))) + (vd(0) * mc) + (vd(0) * mp) - (vd(1) * mp * l * cos(q(1)))) 
(0.10000000000000001 * v(1) - (vd(0) * mp * l * cos(q(1))) + (vd(1) * mp * pow(l, 2)) + 9.8100000000000005 * (mp * l * sin(q(1))))
        </code></pre></p>

        <p>Go ahead and compare these with the <a
        href="acrobot.html#cart_pole">cart-pole equations</a> that we derived
        by hand.</p>

        <p>Drake offers a method <a
        href="https://drake.mit.edu/doxygen_cxx/namespacedrake_1_1symbolic.html#ae8c85e424b3109ed84a5bb309238bc3c"><code>DecomposeLumpedParameters</code></a>
        that will take this expression and factor it into the affine expression
        above.  For this cart-pole example, it extracts the lumped parameters
        $[ m_c + m_p, m_p l, m_p l^2 ].$</p>

      </example>

      <p>The existence of the lumped-parameter decomposition reveals that the
      <i>equation error</i> for lumped-parameter estimation, with the error
      taken in the torque coordinates, can be solved using least squares.  As
      such, we can leverage all of the strong results and variants from linear
      estimation.  For instance, we can add terms to regularize the estimate
      (e.g. to stay close to an initial guess), and we can write efficient
      recursive estimators for optimal online estimation of the parameters
      using recursive least-squares.  My favorite recursive least-squares
      algorithm uses incremental QR factorization<elib>Kaess08</elib>.</p>

      <p>Importantly, because we have reduced this to a least-squares problem,
      we can also understand when it will <i>not</i> work.  In particular, it
      is quite possible that some parameters cannot be estimated from any
      amount of joint data taken on the robot.  As a simple example, consider a
      robotic arm bolted to a table; the inertial parameters of the first link
      of the robot will not be identifiable from any amount of joint data. Even
      on the second link, only the inertia relative to the first joint axis
      will be identifiable; the inertial parameters corresponding to the other
      dimensions will not.  In our least-squares formulation, this is quite
      easy to understand: we simply check the (column) rank of the data matrix,
      ${\bf W}$.  In particular, we can extract the <b>identifiable lumped
      parameters</b> by using, e.g., $\bR_1\alpha_l$ from the QR factorization:
      $${\bf W} = \begin{bmatrix} \bQ_1 & \bQ_2 \end{bmatrix} \begin{bmatrix}
      \bR_1 \\ 0 \end{bmatrix}, \quad \Rightarrow \quad {\bf W}\balpha_l =
      \bQ_1 (\bR_1 \alpha_l).$$</p>

      <example><h1>Parameter estimation for the Cart-Pole</h1>

        <p>Having extracted the lumped parameters from the URDF file above, we
        can now take this to fruition.  I've kept the example simple: I've
        simulated the cart-pole for a few seconds running just simple sine wave
        trajectories at the input, then constructed the data matrix and
        performed the least squares fit.</p>

        <p><a target="sysid"
          href="https://colab.research.google.com/github/RussTedrake/underactuated/blob/master/sysid.ipynb#scrollTo=ASlp7CDoQL5t"><img
          src="https://colab.research.google.com/assets/colab-badge.svg"
          alt="Open In Colab"/></a>
            </p>

        <p>The output looks like this: <pre><code>Estimated Lumped Parameters:
(mc + mp).  URDF: 11.0,  Estimated: 10.905425349337081
(mp * l).  URDF: 0.5,  Estimated: 0.5945797067753813
(mp * pow(l, 2)).  URDF: 0.25,  Estimated: 0.302915745122919</code></pre>
          Note that we could have easily made the fit more accurate with more
          data (or more carefully selected data).</p>            

      </example>

      <p>Should we be happy with only estimating the (identifiable) lumped
      parameters?  Isn't it the true original parameters that we are after? The
      linear algebra decomposition of the data matrix (assuming we apply it to
      a sufficiently rich set of data), is actually revealing something
      fundamental for us about our system dynamics. Rather than feel
      disappointed that we cannot accurately estimate some of the parameters,
      we should embrace that <i>we don't need to estimate those parameters</i>
      for any of the dynamic reasoning we will do about our equations
      (simulation, verification, control design, etc).  The identifiable lumped
      parameters are precisely the subset of the lumped parameters that we
      need.</p>

      <p>For practical reasons, it might be convenient to take your estimates
      of the lumped parameters, and try to back out the original parameters
      (for instance, if you want to write them back out into a URDF file).  For
      this, I would recommend a final post-processing step that e.g. finds the
      parameters $\hat{\balpha}$ that are as close as possible (e.g. in the
      least-squares sense) to your original guess for the parameters, subject
      to the nonlinear constraint that $\bR_1 \balpha_l(\hat{\balpha})$ matches
      the estimated identifiable lumped parameters.
      </p>

    </subsection>

    <subsection><h1>Identification using energy instead of torque.</h1>
    
      <!-- Great question!  I should have been more careful with my words.  A more accurate statement would have been "rather than do finite differences in joint velocities, we can do finite differences in energy which is more numerically robust".  

      I haven't gotten to writing this part of the notes yet, but hope to catch up soon.  The approach I was describing is from https://ieeexplore.ieee.org/abstract/document/619069 .
      -->

    </subsection>

    <subsection><h1>Optimal Experiment Design</h1></subsection>


    <todo>Residual models with linear function approximators.  E.g. Sanner and Slotine.  https://ieeexplore.ieee.org/abstract/document/4791778/?casa_token=2F5kRNSQvokAAAAA:QLmN69TxNQWr9AhL8KgV7wCFP-M1WhMZpk7NG-dThSr5VkwWu7Vmwn6ulYejaoZfGIaS7e4zzQ </todo>

    <todo>Adaptive control (for underactuated; e.g. Joe Moore's paper Moore14)</todo>

    <todo>Patrick Wensing's inertia identification constraints</todo>

    <subsection><h1>Identification with contact</h1></subsection>

  </section>

  <section><h1>Linear state-space models</h1>
  
    <subsection><h1>From state observations</h1>
      
      <todo>model-order reduction</todo>
    
    </subsection>

    <subsection><h1>From input-output data</h1>
    
      <todo>Ho-Kalman</todo>
      <todo>Subspace identification</todo>
    
    </subsection>

    <subsection><h1>Adding stability constraints</h1></subsection>

  </section>

  <section><h1>Linear ARMAX models</h1></section>

  <section><h1>Piecewise-affine models / hybrid system i.d.</h1></section>

  <section><h1>Nonlinear system identification</h1>
  
    <todo>Neural Nets / Intuitive physics / etc.</todo>
    <todo>MMT / Jack's work</todo>
  
  </section>



  <section><h1>Task-relevant models</h1></section>

</chapter>
<!-- EVERYTHING BELOW THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->

<div id="references"><section><h1>References</h1>
<ol>

<li id=Khalil04>
<span class="author">W Khalil and E Dombre</span>,
<span class="title">"Modeling, Identification and Control of Robots"</span>,Elsevier
, <span class="year">2004</span>.

</li><br>
<li id=Kaess08>
<span class="author">M. Kaess and A. Ranganathan and F. Dellaert</span>,
<span class="title">"i{SAM}: Incremental Smoothing and Mapping"</span>,
<span class="publisher">IEEE Transactions on Robotics</span>, vol. 24, no. 6, pp. 1365-1378, <span class="year">2008</span>.

</li><br>
</ol>
</section><p/>
</div>

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=contact.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=state_estimation.html>Next Chapter</a></td>
</tr></table>

<div id="footer">
  <hr>
  <table style="width:100%;">
    <tr><td><a href="https://accessibility.mit.edu/">Accessibility</a></td><td style="text-align:right">&copy; Russ
      Tedrake, 2021</td></tr>
  </table>
</div>


</body>
</html>
