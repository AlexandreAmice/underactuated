{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides examples to go along with the [textbook](http://underactuated.csail.mit.edu/lqr.html).  I recommend having both windows open, side-by-side!\n",
    "\n",
    "[Click here](http://underactuated.csail.mit.edu/drake.html#notebooks) for instructions on how to run the notebook on Deepnote and/or Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import Math, clear_output, display\n",
    "from pydrake.all import (DiscreteAlgebraicRiccatiEquation,\n",
    "                         DiscreteTimeLinearQuadraticRegulator,\n",
    "                         LinearQuadraticRegulator, ToLatex)\n",
    "\n",
    "from underactuated import running_as_notebook\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete-time vs continuous-time LQR\n",
    "\n",
    "Let's compare the two solutions in our simplest of systems: the double integrator.\n",
    "\n",
    "## Continuous time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ct_demo():\n",
    "    A = np.array([[0,1],[0,0]])\n",
    "    B = np.array([[0],[1]])\n",
    "    Q = np.identity(2)\n",
    "    R = np.identity(1)\n",
    "\n",
    "    K,S = LinearQuadraticRegulator(A,B,Q,R)\n",
    "    display(Math(f\"S = {ToLatex(S)}\\n\"))\n",
    "\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(S)\n",
    "    display(Math(f\"eig(S) = {ToLatex(eigenvalues)}\\n\"))\n",
    "\n",
    "ct_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt_demo(h=1):\n",
    "    A = np.array([[1,h],[0,1]])\n",
    "    B = np.array([[0],[h]])\n",
    "    Q = h*np.identity(2)\n",
    "    R = h*np.identity(1)\n",
    "\n",
    "    K,S = DiscreteTimeLinearQuadraticRegulator(A,B,Q,R)\n",
    "    display(Math(f\"S = {ToLatex(S)}\\n\"))\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(S)\n",
    "    display(Math(f\"eig(S) = {ToLatex(eigenvalues)}\\n\"))\n",
    "\n",
    "dt_demo(h=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few things to notice here.  First, the discrete-time solution converges to the continuous-time solution as the timestep goes to zero.  Second, the cost-to-go is always higher in the discrete-time version: you should think of the discrete time as adding an additional constraint that the control decision can only be changed once per timestep.  Adding constraints can only increase the total cost.\n",
    "\n",
    "### Side note: Algebraic solution\n",
    "\n",
    "In the DP chapter, I was able to give a nice closed-form solution for the continuous-time case:$$S = \\begin{bmatrix} \\sqrt{3} & 1 \\\\ 1 & \\sqrt{3} \\end{bmatrix}.$$  The discrete-time case is not as clean.  Even when $h=1$, the discrete-time Riccati equation, using $$S = \\begin{bmatrix} a & b \\\\ b & c \\end{bmatrix},$$ results in three equations: \\begin{gather*} b^2 = 1+c \\\\ 1 + c + bc = a + ac \\\\ c^2 = 2b + a + ac. \\end{gather*}  With a little work, you can reduce this to to a quadratic equation in $b$, with a solution, $b = \\frac{1}{4}(1 + \\sqrt{21} + \\sqrt{2(3+\\sqrt{21})}).$  Not so nice! \n",
    "\n",
    "### Side note: Exact integration\n",
    "\n",
    "One can also use the exact integral of the linear system $e^Ah$ in the discretization, instead of the Euler discretization.  It doesn't change the basic observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LQR via Fitted Value Iteration\n",
    "\n",
    "Double integrator.  Discrete-time, infinite-horizon, discounted.  This is the \"traditional\" fitted value iteration, $J=x^TSx$ as the (linear) function approximator.  Is samples both $x$ and $u$, and takes an argmin over the samples $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the double integrator\n",
    "timestep = 0.1\n",
    "A = np.eye(2) + timestep*np.array([[0., 1.], [0., 0.]])\n",
    "B = timestep*np.array([[0.], [1.]])\n",
    "Q = timestep*np.eye(2)\n",
    "R = timestep*np.eye(1)\n",
    "\n",
    "def quadratic_regulator_cost(x, u):\n",
    "    return (x * (Q @ x)).sum(axis=0) + (u * (R @ u)).sum(axis=0)\n",
    "\n",
    "def FittedValueIteration(S_guess, gamma=0.9):\n",
    "\n",
    "    S_optimal = DiscreteAlgebraicRiccatiEquation(A=np.sqrt(gamma) * A,\n",
    "                                                 B=B,\n",
    "                                                 Q=Q,\n",
    "                                                 R=R / gamma)\n",
    "\n",
    "    x1s = np.linspace(-5,5,31)\n",
    "    x2s = np.linspace(-4,4,31)\n",
    "    us = np.linspace(-1,1,9)\n",
    "    Us, X1s, X2s = np.meshgrid(us, x1s, x2s, indexing='ij')\n",
    "    XwithU = np.vstack((X1s.flatten(), X2s.flatten()))\n",
    "    UwithX = Us.flatten().reshape(1,-1)\n",
    "    Nx = x1s.size * x2s.size\n",
    "    X = XwithU[:,:Nx]\n",
    "    N = X1s.size\n",
    "\n",
    "    Xnext = A @ XwithU + B @ UwithX\n",
    "    G = quadratic_regulator_cost(XwithU, UwithX)\n",
    "    Jnext = np.zeros((1,N))\n",
    "    Jd = np.zeros((1,Nx))\n",
    "\n",
    "    def cost_to_go(S, X):\n",
    "        return (X * (S @ X)).sum(axis=0)  # vectorized quadratic form\n",
    "\n",
    "    def mean_bellman_residual(S, X, J_desired):\n",
    "        N = J_desired.size\n",
    "        err = cost_to_go(S, X) - J_desired\n",
    "        loss = np.mean(err**2) # == 1/N ∑ᵢ [tr(Sxᵢxᵢ')-yᵢ]²\n",
    "        # dloss_dS = 2/N ∑ᵢ errᵢ*xᵢxᵢ' = 2/N X*Diag(err)*X'\n",
    "        dloss_dS = 2/N * X @ np.diag(err.reshape(-1,)) @ X.T\n",
    "        return loss, dloss_dS\n",
    "\n",
    "    S = S_guess\n",
    "    eta = 0.0001\n",
    "    last_loss = np.inf\n",
    "    for epoch in range(1000 if running_as_notebook else 2):\n",
    "        Jnext = cost_to_go(S, Xnext)\n",
    "        Jd[:] = np.min((G + gamma*Jnext).reshape(us.size, Nx), axis=0)\n",
    "        for i in range(10):\n",
    "            loss, dloss_dS = mean_bellman_residual(S, X, Jd)\n",
    "            S -= eta*dloss_dS\n",
    "        clear_output(wait=True)\n",
    "        print(f\"epoch {epoch}: loss = {loss}, S = {S.flatten()}\")\n",
    "        if np.linalg.norm(last_loss - loss) < 1e-8:\n",
    "            break\n",
    "        last_loss = loss\n",
    "\n",
    "    print(f\"eigenvalues of S: {np.linalg.eig(S)[0]}\")\n",
    "    print(f\"optimal S= {S_optimal.flatten()}\")\n",
    "\n",
    "\n",
    "FittedValueIteration(S_guess=np.eye(2), gamma=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the initial guess of $S$ and the discount factor $\\gamma$ that I've used above, the algorithm converges nicely.  You'll see that it is close to the optimal $S$, but not exactly the optimal $S$.\n",
    "\n",
    "Interestingly, if you choose $\\gamma$ to be much closer to 1, the algorithm will diverge. At some point, the sampled values over $u$ cause problems -- the Bellman equation does not actually have a steady-state solution for the discretized $u$ version of the problem (the cost-to-go is infinite).\n",
    "\n",
    "To convince you that this is indeed the problem, here is a version that solves analytically for the optimal $u$ (given the estimated $S$).  It draws samples only over $x$, and converges beautifully to the true optimum, even when $\\gamma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FittedValueIteration(S_guess, gamma=0.9):\n",
    "\n",
    "    S_optimal = DiscreteAlgebraicRiccatiEquation(A=np.sqrt(gamma) * A,\n",
    "                                                 B=B,\n",
    "                                                 Q=Q,\n",
    "                                                 R=R / gamma)\n",
    "\n",
    "    x1s = np.linspace(-5,5,31)\n",
    "    x2s = np.linspace(-4,4,31)\n",
    "    X1s, X2s = np.meshgrid(x1s, x2s, indexing='ij')\n",
    "    X = np.vstack((X1s.flatten(), X2s.flatten()))\n",
    "    N = X1s.size\n",
    "\n",
    "    Jd = np.zeros((1,N))\n",
    "\n",
    "    def cost_to_go(S, X):\n",
    "        return (X * (S @ X)).sum(axis=0)  # vectorized quadratic form\n",
    "\n",
    "    def policy(S, X):\n",
    "        return -gamma*np.linalg.inv(R + gamma*B.T @ S @ B) @ B.T @ S @ A @ X\n",
    "\n",
    "    def mean_bellman_residual(S, X, J_desired):\n",
    "        N = J_desired.size\n",
    "        err = cost_to_go(S, X) - J_desired\n",
    "        loss = np.mean(err**2) # == 1/N ∑ᵢ [tr(Sxᵢxᵢ')-yᵢ]²\n",
    "        # dloss_dS = 2/N ∑ᵢ errᵢ*xᵢxᵢ' = 2/N X*Diag(err)*X'\n",
    "        dloss_dS = 2/N * X @ np.diag(err.reshape(-1,)) @ X.T\n",
    "        return loss, dloss_dS\n",
    "\n",
    "    S = S_guess\n",
    "    eta = 0.0001\n",
    "    last_loss = np.inf\n",
    "    for epoch in range(1000 if running_as_notebook else 2):\n",
    "        U = policy(S, X)\n",
    "        Xnext = A @ X + B @ U\n",
    "        G = quadratic_regulator_cost(X, U)\n",
    "        Jd = G + gamma*cost_to_go(S, Xnext)\n",
    "        for i in range(10):\n",
    "            loss, dloss_dS = mean_bellman_residual(S, X, Jd)\n",
    "            S -= eta*dloss_dS\n",
    "        clear_output(wait=True)\n",
    "        print(f\"epoch {epoch}: loss = {loss}, S = {S.flatten()}\")\n",
    "        if np.linalg.norm(last_loss - loss) < 1e-8:\n",
    "            break\n",
    "        last_loss = loss\n",
    "\n",
    "    print(f\"eigenvalues of S: {np.linalg.eig(S)[0]}\")\n",
    "    print(f\"optimal S= {S_optimal.flatten()}\")\n",
    "    return S\n",
    "\n",
    "\n",
    "FittedValueIteration(S_guess=np.eye(2), gamma=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
